![](https://img.shields.io/badge/language-python-orange.svg)

# Implement-SLAM-with-RGBD-measurements



Implement simultaneous localization and mapping (SLAM) using odometry,  inertial,  2-D laser
range, and RGBD measurements from a humanoid robot. Use the IMU, odometry, and laser measurements
to localize the robot and build a 2-D occupancy grid map of the environment.  Use the RGBD information
to color the floor of your 2-D map.

Here are some SLAM Results:

![image0](./0.png)
![image4](./4.png)



## Here is instruction for this project. I used Python3.6
load_data.py is the function loading the data sets, including lidar, joint, and cam data
main.py is my core code. Runing it you will get the plot for the testset data  map.
Particle_filter.py is the funtions which including softmax function, resampling function, and particle filter function
test_texture.py is for the texture mapping part.






[![](https://img.shields.io/badge/常联系-click_for_contact-green.svg)](https://github.com/l5shi/__Overview__/blob/master/thanks/README.md)
[![](https://img.shields.io/badge/Donate-支付宝|微信|Venmo-blue.svg)](https://github.com/l5shi/__Overview__/blob/master/thanks/README.md)
